üöÄ Proyecto Final: Ingenier√≠a de Datos e IA con DatabricksT√≠tulo del Proyectoguaru/project-databricksDescripci√≥n: Este repositorio contiene la implementaci√≥n completa de un pipeline de ETL para datos de vuelos, utilizando Databricks Unity Catalog para la gobernanza de datos y GitHub Actions para la automatizaci√≥n del Continuous Integration/Continuous Deployment (CI/CD) y la orquestaci√≥n del workflow.üèóÔ∏è Arquitectura de Datos (Medall√≥n)El proyecto utiliza la Arquitectura de Medall√≥n (o capas de datos) para garantizar la calidad, consistencia y trazabilidad de los datos en todas sus etapas de procesamiento.adjunta imagen: Diagrama de arquitectura de Medall√≥n (Bronze, Silver, Golden)CapaEsquemaContenido y Prop√≥sitoBronzefinal_project_flights.bronzeIngesta sin procesar. Datos tal como son le√≠dos del origen (Azure Data Lake Storage), sin transformaciones ni validaciones de tipo.Silverfinal_project_flights.silverDatos limpios y enriquecidos. Datos consolidados y estandarizados. Se eliminan nulos y se aplican filtros de calidad.Goldenfinal_project_flights.goldenDatos listos para consumo. Tablas de dimensi√≥n y de hechos agregados, optimizadas para an√°lisis de negocio, BI y Machine Learning (e.g., RPT_RESUMEN_VUELOS_DIARIO).‚öôÔ∏è Pipeline de CI/CD (GitHub Actions)El proceso de despliegue est√° completamente automatizado a trav√©s del workflow script_Prod.yml.Flujo del DespliegueCada push o merge a la rama main ejecuta un workflow que garantiza que el entorno de Producci√≥n en Databricks est√© sincronizado con el c√≥digo aprobado.Exportaci√≥n: Los notebooks se exportan en modo SOURCE desde el workspace de Desarrollo (no visible en el script final, pero es el paso previo l√≥gico).Despliegue: Los notebooks exportados (sin extensi√≥n .py en Databricks) se suben al workspace de Producci√≥n en la ruta /Proyecto_Flights.Creaci√≥n de Job: Se crea o actualiza el workflow WF_ADB a trav√©s de la API de Databricks Jobs, adjunt√°ndolo al cluster existente ($CLUSTER_ID).Ejecuci√≥n: El workflow se ejecuta inmediatamente despu√©s del despliegue para validar el c√≥digo en el entorno de Producci√≥n.adjunta imagen: Captura de pantalla del log de GitHub Actions mostrando los pasos de despliegueüìä Orquestaci√≥n del Workflow (WF_ADB)El workflow WF_ADB orquesta la secuencia de ETL en el cluster de Producci√≥n. Est√° dise√±ado con una l√≥gica de dependencias y una etapa de mitigaci√≥n de fallos para proteger la capa Golden.adjunta imagen: Diagrama de la secuencia del Job en Databricks (Conectores de tareas)Estructura de TareasTareaNotebook / ComandoFunci√≥nL√≥gica de Fallo (Key Feature)1_PreparacionPreparacion_CatalogoCrea el cat√°logo y los esquemas (bronze, silver, golden) y configura storage locations.N/A2_Raw_to_Bronze1_raw_to_bronzeCarga inicial de datos crudos.Depende de 1_Preparacion.3_Bronze_to_Silver2_bronze_to_silverLimpieza, estandarizaci√≥n y cast de tipos de datos.Depende de 2_Raw_to_Bronze.4_Silver_to_Golden3_silver_to_goldenAgregaci√≥n final y creaci√≥n de tablas de reporte. (Requiere CAST expl√≠cito para evitar errores de tipo LONG vs DOUBLE).Depende de 3_Bronze_to_Silver.5_GrantsGrantsOtorga permisos SELECT a los grupos de consumo (Desarrolladores).Depende de 4_Silver_to_Golden.6_FALLBACK_REVOKERevokeRevocaci√≥n de Permisos. Se ejecuta SOLO SI At Least One Failed en las tareas anteriores, garantizando que los usuarios no lean datos si la ejecuci√≥n del ETL no fue completa.Depende de 1, 2, 3, 4 y 5.üîë Configuraci√≥n del EntornoPara que el workflow de GitHub Actions se ejecute correctamente, deben definirse los siguientes Secrets en la configuraci√≥n del repositorio:SecretoDescripci√≥nPermisos Requeridos en TokenDATABRICKS_DEST_HOSTURL del Workspace de Producci√≥n.N/ADATABRICKS_DEST_TOKENToken de Acceso Personal para Producci√≥n.Workspace: READ, Jobs: READ/WRITE, Clusters: CAN_USECLUSTER_IDID del cluster existente (1208-045016-u4soz08w) al que se adjuntar√°n las tareas.Clusters: CAN_ATTACH_TO
